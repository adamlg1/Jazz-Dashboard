# Jazz-Dashboard
Final Project for Database Modeling Concepts

System Design -
![ChatGPT Image Apr 10, 2025, 10_47_05 PM](https://github.com/user-attachments/assets/fa68dbd5-8755-429b-9983-d359f27289eb)

Here is my tech stack as generated by chatgpt. It didn't do half bad.
I am currently running the application locally, but this would obviously have to move to a hosted DNS. That will likely come after the class has concluded.

Why this project is interesting to me -

My 5th grade self would be very proud of this project. In Elementary school, my reading level hit too high, and my teachers told me to read whatever I wanted. I would usually pick to go read the basketball books after I had finished my class assignments (when I did not get distracted by talking to people of course). I just thought it would be fun to build a website that goes along with the Jazz since I'm a big fan.


Summary of project -

This was initially going to be focused on manipulating the data that I had received from Basketball reference, but that seemed too simple. The project has a stats dashboard with dropdowns to sort the data, but it also has a chatbot that will talk about the jazz with you given the latest data (in my testing, you can't trick it to talk about other topics, it has seemed to do well at staying firm). Finally, the project has supabase authentication, along with jwt tokens to manage user sessions and limit what they are able to access.

Key Learnings - 

 * Try new technologies, they can be a lot of fun!
 * Work on something that's interesting to you, even if it's just your 5th grade dream.
 * We greatly overestimate the amount of work we are going to get done lol. Hopefully I can improve in that way.


How I would make this system scale -

![image](https://github.com/user-attachments/assets/73608ba0-44bb-49f0-8063-406595f2e12a)


I would eventually hook up the system to AWS. There was not enough time in this project for me to get everything set up here. The node.js backend could scale using Amazon ELB, frontend could work using CDN (cloudfront), to scale the supabase database to a lot more users, I could use a Redis cache (or I could just switch to RDS). The OpenAI integration would have limitations, mostly because I am not rich. That feature would be money losing, and I would eventually have to restrict it to admins so that I wouldn't get broke paying for people to use it.












Before coding design -
Workflow -

Sketch of initial thinking on my ERD and the data your project will be accessing and using (will replace this with an electronically made ERD diagram over the course of the project)
![IMG_0256](https://github.com/user-attachments/assets/e5ad3afb-2b8a-4755-baa4-801d39a6304f)

Sketch rough system design of your project, what are the technologies and pieces (shapes) and interactions (arrows) (this will also ideally be replaced over the course of the project)
![IMG_0255](https://github.com/user-attachments/assets/adfef1a4-269f-466b-8f9d-81f74c836f09)
I will be using python beautiful soup instead of my initial ideas. It seems to be the best way, and I will most likely scrape Basketball reference.

## Goals for where I want my project to be at the following dates:
* 3/19 - Ugly website up, script scraping ESPN/Basketball Reference sort of working (at least grabs some data, not everything)
* 3/26 - Script to scrape for recent data works, and runs at a consistent time each day. User can view previous days of data as well.
* 4/2 - Prettying website, potentially have script pull the latest article on the Utah Jazz as well.
* 4/9 - Implement logging in, and store passwords securely through bcrypt and AWS dynamodb. 
* 4/16 - (hopefully have tested all along the way) Check all tests have a positive and negative case, load test, and fix security vulnerabilities.

Please include any additional relevant information you'd like to include or have. The website will be fairly simple as far as UX, but it will have the player's faces by the leading scorer and other stats for that day/week. I would like to store the stats historically, and hopefully be able to filter them by week. This will likely take going backwards and adding some data to test the website.

3/19 
* The script is grabbing data, and converting it into a csv file. I have not yet made the script run on a consistent time scale, nor have I set up my database configuration yet. The basics for connecting the backend and frontend are working. This should be leading me to being able to develop the frontend aspects, and then start making my queries based off of user input.
![image](https://github.com/user-attachments/assets/5e6518e1-7bc1-49e4-8e58-f7cc8d62594a)

4/7
Update - This website's focus has changed slightly from what it was before. Instead of storing everything on AWS, I have decided to use supabase so that I could gain experience using that. Currently, the script is able to scrape basketball reference, insert everything into supabase, and then the frontend is able to display those stats. The latest stats are fed to gpt, and I have a chatbot working right now. I might try to make it so the user can upload a background image for the chat in a settings tab. The next step is potentially storing the user chats, and implementing the login screen so that when unauthenticated, the user can only access the login and about pages. I'm hoping to come up with some other cool features before next Monday when I present as well. However, I have been able to make good progress on the website and believe it will seem pretty cool. At least 5th grade me would be proud.

4/10 
2 pm update - User login is working through supabase (you need to verify your account through their email), stats page is not accessible without logging in, chatbot is not available without logging in, and the MVP is here. The chatbot is using gpt 4o, and it is being fed the stats that are scraped from basketball reference.

work to be completed - 
* need to change the jwt token authentication from local storage to http cookies instead to prevent an XSS attack.
* Set up cron job, and add filter to geet the stats by the date they were scraped (I have been manually running the script)
* set up page to notify the user to login instead of just redirecting them to the login page when unauthorized - done !
* various toast messages to notify the user of what is going on - I believe this is sufficient outside of when the user creates an account they need to verify their email
* scraping more data from basketball reference and running more complex queries - this will come, likely after the class

4/10 
11 pm update - Presentation should be ready, I need to update the readme with screenshots/a screen recording of the website. This was a really fun project to do, and I have enjoyed working on it so far.
